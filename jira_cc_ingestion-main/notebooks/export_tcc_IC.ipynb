{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7783ce2d-ae5c-4d45-8078-1175699c36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf21397-2fcb-413e-b136-6a08305c35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "from jira_cc_ingestion.application.get_from_db import (get_extraction_depth, get_last_row)\n",
    "from jira_cc_ingestion.application.extract_from_jira import (retrieve_raw_issues, process_issues,\n",
    "                                                             retrieve_deleted_issue_keys, get_sprints_data,\n",
    "                                                             get_todo_deleted_list, get_worklog_deleted_list,\n",
    "                                                             get_users_data, retrieve_worklogs, retrieve_to_do_list)\n",
    "from jira_cc_ingestion.application.load_to_db import (loading_info, tag_deleted, delete_insert_sprints_data,\n",
    "                                                     loading_deleted_todo, loading_deleted_worklog,\n",
    "                                                     delete_insert_users_data)\n",
    "from jira_cc_ingestion.infra.jira import JiraData\n",
    "from jira_cc_ingestion.infra.sql_db import DatabaseHelper\n",
    "#from jira_cc_ingestion.config import MSSQL_DB, MSSQL_SERVER, PORT\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a65ec918-b167-4d05-81fc-2541fee62a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c368b885-4422-48b6-bc96-2bd6a73b525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_auth = 'OuxnJVJx41OING5vgcncvXLbcS47EwXYvkPX5h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80ab40c1-4424-40aa-9687-60d65a48256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = {'name': \"TCC\",\n",
    "               'jira_url': 'https://devstack.vwgroup.com/jira',\n",
    "               \"additional_conditions\": 'AND Type = Test AND \"KPM-Tickets to test\" is not Empty and created >= \"2024-01-01\"',\n",
    "               'sql_table_issue': 'raw_jira_technica_TCC_daily',\n",
    "               'list_of_direct_fields': [\n",
    "                   {'field': 'key', 'corresponding_customfield': 'key',\n",
    "                    'method_of_extraction': 'direct_retrieval'},\n",
    "                   {'field': 'changelog_history', 'corresponding_customfield': 'changelog',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['histories', False]}\n",
    "               ],\n",
    "               'list_of_fields': [\n",
    "                   {'field': 'New KPM Tickets', 'corresponding_customfield': 'customfield_34603',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'KPM-Tickets to test', 'corresponding_customfield': 'customfield_52954',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                    {'field': 'description', 'corresponding_customfield': 'description',\n",
    "                   'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'assignee', 'corresponding_customfield': 'assignee',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['displayName']},\n",
    "                   {'field': 'reporter', 'corresponding_customfield': 'reporter',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['displayName']},\n",
    "                   {'field': 'components', 'corresponding_customfield': 'components',\n",
    "                    'method_of_extraction': 'list_field_retrieval_value',\n",
    "                    'arguments': ['name']},\n",
    "                   {'field': 'due_date', 'corresponding_customfield': 'duedate',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'description', 'corresponding_customfield': 'description',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'epic_link', 'corresponding_customfield': 'customfield_10000',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'status', 'corresponding_customfield': 'status',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['name']},\n",
    "                   {'field': 'priority', 'corresponding_customfield': 'priority',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['name']},\n",
    "                   {'field': 'resolution', 'corresponding_customfield': 'resolution',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['name']},\n",
    "                   {'field': 'issue_type', 'corresponding_customfield': 'issuetype',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['name']},\n",
    "                   {'field': 'project', 'corresponding_customfield': 'project',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['key']},\n",
    "                   {'field': 'parent', 'corresponding_customfield': 'parent',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['key']},\n",
    "                   {'field': 'issue_id', 'corresponding_customfield': 'issuetype',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['id']},\n",
    "                   {'field': 'sprint_names', 'corresponding_customfield': 'customfield_10004',\n",
    "                    'method_of_extraction': 'list_field_retrieval_sprints',\n",
    "                    'arguments': ['name']},\n",
    "                   {'field': 'sprint_ids', 'corresponding_customfield': 'customfield_10004',\n",
    "                    'method_of_extraction': 'list_field_retrieval_sprints',\n",
    "                    'arguments': ['id']},\n",
    "                   {'field': 'sprints_startDate', 'corresponding_customfield': 'customfield_10004',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_sprint',\n",
    "                    'arguments': ['startDate', 0]},\n",
    "                   {'field': 'sprint', 'corresponding_customfield': 'customfield_10004',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_sprint',\n",
    "                    'arguments': ['name', 0]},\n",
    "                   {'field': 'sprint_id', 'corresponding_customfield': 'customfield_10004',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_sprint',\n",
    "                    'arguments': ['id', 0]},\n",
    "                   {'field': 'last_sprint', 'corresponding_customfield': 'customfield_10004',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_sprint',\n",
    "                    'arguments': ['name', -1]},\n",
    "                   {'field': 'last_sprint_id', 'corresponding_customfield': 'customfield_10004',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_sprint',\n",
    "                    'arguments': ['id', -1]},\n",
    "                   {'field': 'timespent', 'corresponding_customfield': 'timespent',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'Technology', 'corresponding_customfield': 'customfield_45200',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['value']},\n",
    "                   {'field': 'Cluster', 'corresponding_customfield': 'customfield_18401',\n",
    "                    'method_of_extraction': 'field_arg_retrieval_value',\n",
    "                    'arguments': ['value']},\n",
    "                   {'field': 'summary', 'corresponding_customfield': 'summary',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'updated', 'corresponding_customfield': 'updated',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'story_points', 'corresponding_customfield': 'customfield_10508',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'resolution_date', 'corresponding_customfield': 'resolutiondate',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'created', 'corresponding_customfield': 'created',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'labels', 'corresponding_customfield': 'labels',\n",
    "                    'method_of_extraction': 'list_field_retrieval'},\n",
    "                   {'field': 'SW', 'corresponding_customfield': 'customfield_31804',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'ecu', 'corresponding_customfield': 'customfield_51500',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'Last comment', 'corresponding_customfield': 'customfield_19508',\n",
    "                    'method_of_extraction': 'field_arg_retrieval'},\n",
    "                   {'field': 'Acceptance Criterias name', 'corresponding_customfield': 'customfield_10335',\n",
    "                    'method_of_extraction': 'list_field_retrieval_value',\n",
    "                    'arguments': ['name']},\n",
    "                   {'field': 'Acceptance Criterias checks', 'corresponding_customfield': 'customfield_10335',\n",
    "                    'method_of_extraction': 'list_field_retrieval_value',\n",
    "                    'arguments': ['checks']},\n",
    "                    {'field': 'comments_dates', 'corresponding_customfield': 'comment',\n",
    "                     'method_of_extraction': 'extract_simplified_comments',\n",
    "                     'arguments': [[('created',)], False]},\n",
    "               ],\n",
    "               'list_date_fields': [\n",
    "                   'created',\n",
    "                   'updated',\n",
    "                   'due_date',\n",
    "                   'resolution_date'\n",
    "               ]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6993f90d-5088-49bd-80f7-6ec917da15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "675cb849-e5f6-46c6-83ef-89d207769c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to connect to the jira server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Jira Issues...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate issues  and configured fields are extracted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting of needed fields for the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m project...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m extracted_issues \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_issues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43missues_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_datetime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#extracted_issues.to_csv(\"extracted_issues_all_resolution_20241025.csv\", index=False, header=1, sep=\";\")\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\jira_cc_ingestion\\notebooks\\..\\jira_cc_ingestion\\application\\extract_from_jira.py:78\u001b[0m, in \u001b[0;36mprocess_issues\u001b[1;34m(project_dict, issues_list, current_datetime)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_issues\u001b[39m(project_dict, issues_list, current_datetime):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"processing issues to generate a dataframe contains issues information\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     extracted_issues \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m---> 78\u001b[0m         [\n\u001b[0;32m     79\u001b[0m             extract_fields(\n\u001b[0;32m     80\u001b[0m                 project_dict, issue, issue\u001b[38;5;241m.\u001b[39mfields, project_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_of_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m], project_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     81\u001b[0m             )\n\u001b[0;32m     82\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m issue \u001b[38;5;129;01min\u001b[39;00m issues_list\n\u001b[0;32m     83\u001b[0m         ]\n\u001b[0;32m     84\u001b[0m     )\n\u001b[0;32m     85\u001b[0m     extracted_issues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_of_insert\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m current_datetime\n\u001b[0;32m     86\u001b[0m     extracted_issues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeleted\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\PycharmProjects\\jira_cc_ingestion\\notebooks\\..\\jira_cc_ingestion\\application\\extract_from_jira.py:79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_issues\u001b[39m(project_dict, issues_list, current_datetime):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"processing issues to generate a dataframe contains issues information\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     extracted_issues \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     78\u001b[0m         [\n\u001b[1;32m---> 79\u001b[0m             \u001b[43mextract_fields\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m                \u001b[49m\u001b[43mproject_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43missue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43missue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlist_of_fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m issue \u001b[38;5;129;01min\u001b[39;00m issues_list\n\u001b[0;32m     83\u001b[0m         ]\n\u001b[0;32m     84\u001b[0m     )\n\u001b[0;32m     85\u001b[0m     extracted_issues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_of_insert\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m current_datetime\n\u001b[0;32m     86\u001b[0m     extracted_issues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeleted\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\PycharmProjects\\jira_cc_ingestion\\notebooks\\..\\jira_cc_ingestion\\application\\extract_from_jira.py:145\u001b[0m, in \u001b[0;36mextract_fields\u001b[1;34m(project_dict, issue, fields_dict, list_of_fields, project_name)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_fields\u001b[39m(project_dict, issue, fields_dict, list_of_fields, project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"extract fields\"\"\"\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m     list_info \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(jira_issue_extractor, field_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod_of_extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m])(\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;28mvars\u001b[39m(fields_dict)\u001b[38;5;241m.\u001b[39mget(field_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding_customfield\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m    148\u001b[0m             \u001b[38;5;241m*\u001b[39mfield_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m    149\u001b[0m         )\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m field_dict \u001b[38;5;129;01min\u001b[39;00m list_of_fields\n\u001b[0;32m    151\u001b[0m     ] \u001b[38;5;241m+\u001b[39m [\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(jira_issue_extractor, field_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod_of_extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m])(\n\u001b[0;32m    153\u001b[0m             \u001b[38;5;28mvars\u001b[39m(issue)\u001b[38;5;241m.\u001b[39mget(field_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding_customfield\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m    154\u001b[0m             \u001b[38;5;241m*\u001b[39mfield_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m    155\u001b[0m         )\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m field_dict \u001b[38;5;129;01min\u001b[39;00m project_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_of_direct_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    157\u001b[0m     ]\n\u001b[0;32m    159\u001b[0m     fields_names \u001b[38;5;241m=\u001b[39m ([field_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m field_dict \u001b[38;5;129;01min\u001b[39;00m list_of_fields] \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    160\u001b[0m                     [field_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m field_dict \u001b[38;5;129;01min\u001b[39;00m project_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist_of_direct_fields\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m project_name \u001b[38;5;129;01min\u001b[39;00m PROJECTS:\n",
      "File \u001b[1;32m~\\PycharmProjects\\jira_cc_ingestion\\notebooks\\..\\jira_cc_ingestion\\application\\extract_from_jira.py:146\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_fields\u001b[39m(project_dict, issue, fields_dict, list_of_fields, project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"extract fields\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     list_info \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 146\u001b[0m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjira_issue_extractor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmethod_of_extraction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfields_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcorresponding_customfield\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfield_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marguments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m field_dict \u001b[38;5;129;01min\u001b[39;00m list_of_fields\n\u001b[0;32m    151\u001b[0m     ] \u001b[38;5;241m+\u001b[39m [\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(jira_issue_extractor, field_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod_of_extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m])(\n\u001b[0;32m    153\u001b[0m             \u001b[38;5;28mvars\u001b[39m(issue)\u001b[38;5;241m.\u001b[39mget(field_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding_customfield\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m    154\u001b[0m             \u001b[38;5;241m*\u001b[39mfield_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m    155\u001b[0m         )\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m field_dict \u001b[38;5;129;01min\u001b[39;00m project_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_of_direct_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    157\u001b[0m     ]\n\u001b[0;32m    159\u001b[0m     fields_names \u001b[38;5;241m=\u001b[39m ([field_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m field_dict \u001b[38;5;129;01min\u001b[39;00m list_of_fields] \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    160\u001b[0m                     [field_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m field_dict \u001b[38;5;129;01min\u001b[39;00m project_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist_of_direct_fields\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m project_name \u001b[38;5;129;01min\u001b[39;00m PROJECTS:\n",
      "File \u001b[1;32m~\\PycharmProjects\\jira_cc_ingestion\\notebooks\\..\\jira_cc_ingestion\\infra\\jira_issue_extractor.py:115\u001b[0m, in \u001b[0;36mextract_simplified_comments\u001b[1;34m(comments, list_fields, to_str)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m),(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m     )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    116\u001b[0m         extract_simplified_comment(comment, list_fields)\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(comments)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    118\u001b[0m     ]\n",
      "File \u001b[1;32m~\\PycharmProjects\\jira_cc_ingestion\\notebooks\\..\\jira_cc_ingestion\\infra\\jira_issue_extractor.py:116\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m),(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m     )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 116\u001b[0m         \u001b[43mextract_simplified_comment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(comments)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    118\u001b[0m     ]\n",
      "File \u001b[1;32m~\\PycharmProjects\\jira_cc_ingestion\\notebooks\\..\\jira_cc_ingestion\\infra\\jira_issue_extractor.py:93\u001b[0m, in \u001b[0;36mextract_simplified_comment\u001b[1;34m(comment, list_fields)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_simplified_comment\u001b[39m(\n\u001b[0;32m     91\u001b[0m     comment, list_fields\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m,), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m,), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdated\u001b[39m\u001b[38;5;124m\"\u001b[39m,)]\n\u001b[0;32m     92\u001b[0m ):\n\u001b[1;32m---> 93\u001b[0m     extracted_field \u001b[38;5;241m=\u001b[39m [comment\u001b[38;5;241m.\u001b[39mraw[field[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m list_fields]\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([extracted_field[i][field[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(field) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m extracted_field[i]\n\u001b[0;32m     95\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m i, field \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(list_fields)])\n",
      "File \u001b[1;32m~\\PycharmProjects\\jira_cc_ingestion\\notebooks\\..\\jira_cc_ingestion\\infra\\jira_issue_extractor.py:93\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_simplified_comment\u001b[39m(\n\u001b[0;32m     91\u001b[0m     comment, list_fields\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m,), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m,), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdated\u001b[39m\u001b[38;5;124m\"\u001b[39m,)]\n\u001b[0;32m     92\u001b[0m ):\n\u001b[1;32m---> 93\u001b[0m     extracted_field \u001b[38;5;241m=\u001b[39m [\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m list_fields]\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([extracted_field[i][field[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(field) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m extracted_field[i]\n\u001b[0;32m     95\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m i, field \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(list_fields)])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'c'"
     ]
    }
   ],
   "source": [
    "# logger.info(\"connecting to sql server...\")\n",
    "# connection_string = 'mssql+pyodbc://{}:{}@{}:{}/{}?driver=SQL+Server'.format(user_sql, password_sql, MSSQL_SERVER,\n",
    "#                                                                              PORT, MSSQL_DB)\n",
    "# data_connector = DatabaseHelper(connection_string=connection_string)\n",
    "# logger.info(\"sql server is ready!\")\n",
    "\n",
    "logger.info(\"connecting to jira server...\")\n",
    "jc = JiraData(token=token_auth, jira_url=project['jira_url'])\n",
    "jc.connect_to_jira()\n",
    "logger.info(\"jira server is ready!\")\n",
    "\n",
    "logger.info(\"getting current date...\")\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "logger.info(f\"current date is {current_datetime}\")\n",
    "\n",
    "logger.info(f\"Retrieving extraction depth for {project['name']} project... \")\n",
    "#last_date = get_extraction_depth(data_connector, project, num_update_days)\n",
    "last_date = \"2024-04-01\"\n",
    "logger.info(\n",
    "    f\"Retrieving update issues since {last_date} and configured fields for the {project['name']} project...\")\n",
    "issues_list = retrieve_raw_issues(jc, project, last_date)\n",
    "logger.info(f\"update issues  and configured fields are extracted.\")\n",
    "\n",
    "logger.info(f\"Extracting of needed fields for the {project['name']} project...\")\n",
    "extracted_issues = process_issues(project, issues_list, current_datetime)\n",
    "#extracted_issues.to_csv(\"extracted_issues_all_resolution_20241025.csv\", index=False, header=1, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf49664-e9ee-43c3-b6e5-71a0f1d1faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_issues = process_issues(project, issues_list, current_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca7e4ba4-4f02-472b-8c9d-7b3298f5f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_status_changes(key, changelog_history):\n",
    "    l = [[key, h.created, item.fromString, item.toString] for h in changelog_history for item in h.items  if item.field == \"status\"]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeaf2e2d-a658-46d2-ade5-452409d855e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [[extracted_issues.loc[i, 'key'], h.created, item.fromString, item.toString] for i in range(len(extracted_issues)) \n",
    "     for h in extracted_issues.loc[i, 'changelog_history'] for item in h.items  if item.field == \"status\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d668d98c-c5fc-4502-a2bf-c0d8a133d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(l, columns=['key', 'change_date', 'from_status', 'to_status']).to_csv(\"change_log_tcc.csv\", sep=';', index=False, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7691bbd-e1bf-48f9-8322-faa63fb50fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_issues.apply(lambda x: extract_status_changes(x.key, x.changelog_history), axis=1).explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "224dfd92-58ea-430f-85e3-317c58304946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_diff(d2, d1):\n",
    "    return round((d2 - d1).days + (d2 - d1).seconds /86400, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d692710d-e0fe-4d54-8a2b-1ef48b27d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_w_days(enddate, startdate):\n",
    "    return np.busday_count(startdate, enddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5980e0e6-a57c-4580-9abb-b3827d0ec3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\yassine.hassairi\\.virtualenvs\\jira_cc_ingestion-FUCsZk9i\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'devstack.vwgroup.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "server_time = jc.jira_connector.server_info()[\"serverTime\"]\n",
    "extracted_issues[\"end date\"] = extracted_issues[\"resolution_date\"].map(\n",
    "    lambda d: datetime.datetime.strptime(d[:16], \"%Y-%m-%dT%H:%M\") if d else datetime.datetime.strptime(server_time[:16], \"%Y-%m-%dT%H:%M\"))\n",
    "extracted_issues[\"created\"] = pd.to_datetime(extracted_issues[\"created\"].str[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3baff674-2d96-499d-bff7-f7a38023f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_assignees_info(changelog_history, end_date, current_assignee, created_date):\n",
    "    l = ([(created_date[:16], None)] + [(h.created, item.fromString) for h in changelog_history for item in h.items  if item.field == \"assignee\"]\n",
    "     + [(end_date, current_assignee)])\n",
    "    return (\" | \".join([ str(l[i + 1][1]) + \":\" + str(datetime_diff(datetime.datetime.strptime(l[i + 1][0][:16], \"%Y-%m-%dT%H:%M\"),\n",
    "                                                                   datetime.datetime.strptime(l[i][0][:16], \"%Y-%m-%dT%H:%M\"))) \n",
    "                                                     for i in range(len(l) -1)]), datetime_diff(datetime.datetime.strptime(l[-1][0][:16], \"%Y-%m-%dT%H:%M\"),\n",
    "                                                                                                datetime.datetime.strptime(l[-2][0][:16], \"%Y-%m-%dT%H:%M\")),\n",
    "            datetime.datetime.strptime(l[-2][0][:16], \"%Y-%m-%dT%H:%M\"))\n",
    "\n",
    "def extract_status_info(changelog_history, end_date, current_status, created_date):\n",
    "    l = ([(created_date[:16], None)] + [(h.created, item.fromString) for h in changelog_history for item in h.items  if item.field == \"status\"]\n",
    "     + [(end_date, current_status)])\n",
    "    statuses_list =[(str(l[i + 1][1]), datetime_diff(datetime.datetime.strptime(l[i + 1][0][:16], \"%Y-%m-%dT%H:%M\"),\n",
    "                                                     datetime.datetime.strptime(l[i][0][:16], \"%Y-%m-%dT%H:%M\")))\n",
    "                    for i in range(len(l) -1)]\n",
    "    return datetime_diff(datetime.datetime.strptime(l[-1][0][:16], \"%Y-%m-%dT%H:%M\"),\n",
    "                         datetime.datetime.strptime(l[-2][0][:16], \"%Y-%m-%dT%H:%M\")), [e[1] for e in l].count(\"Test Blocked\"), statuses_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23a1e61b-5087-4779-a251-6dcc2ebd6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignee_extracted_info = extracted_issues.apply(lambda r: extract_assignees_info(r[\"changelog_history\"], r[\"end date\"].strftime(\"%Y-%m-%dT%H:%M\"),\n",
    "                                                                                  r[\"assignee\"], r[\"created\"].strftime(\"%Y-%m-%dT%H:%M\")), axis=1)\n",
    "extracted_issues[\"Assignee history\"] = [l[0] for l in assignee_extracted_info]\n",
    "extracted_issues[\"time with current Assignee\"] = [l[1] for l in assignee_extracted_info]\n",
    "extracted_issues[\"Current assignee date\"] = [l[2] for l in assignee_extracted_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a2feb2d-878a-4a34-b2e2-a07b9a1ef4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_extracted_info = extracted_issues.apply(lambda r: extract_status_info(r[\"changelog_history\"], r[\"end date\"].strftime(\"%Y-%m-%dT%H:%M\"),\n",
    "                                                                                 r[\"status\"], r[\"created\"].strftime(\"%Y-%m-%dT%H:%M\")), axis=1)\n",
    "extracted_issues[\"time in current status\"] =  [round(l[0], 1) for l in status_extracted_info]\n",
    "extracted_issues[\"Status_Blocked_Counter\"] =  [l[1] for l in status_extracted_info]\n",
    "extracted_issues[\"was blocked?\"] = extracted_issues[\"Status_Blocked_Counter\"].map(lambda x: \"x\" if x > 0 else \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "663f5678-2982-45bb-8350-0c566cc6767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses_list = ['Planned', 'Backlog', 'Test Blocked',\n",
    "       'Accepted for Implementation', 'Cancelled', 'Test results ok',\n",
    "       'Implementation Review', 'In Analysis', 'Waiting',\n",
    "       'Provide Documentation', 'In Progress', 'Test results not ok']\n",
    "for status in statuses_list:\n",
    "    extracted_issues[status] = [round(sum([e[1] for e in l[2] if e[0]==status]), 1) for l in status_extracted_info]\n",
    "extracted_issues[\"Total\"] = extracted_issues[\n",
    "        ['Planned', 'Backlog', 'Test Blocked',\n",
    "       'Accepted for Implementation',\n",
    "       'Implementation Review', 'In Analysis', 'Waiting',\n",
    "       'Provide Documentation', 'In Progress']].sum(axis=1).round(1)\n",
    "\n",
    "extracted_issues[\"Total excluding Blocked/Planned\"] = extracted_issues[\n",
    "        ['Backlog', 'Accepted for Implementation',\n",
    "       'Implementation Review', 'In Analysis', 'Waiting',\n",
    "       'Provide Documentation', 'In Progress']].sum(axis=1).round(1)\n",
    "\n",
    "extracted_issues[\"Percentage time in Deffect Discussion\"] = (extracted_issues['Implementation Review'] \n",
    "                                                             / extracted_issues[\"Total excluding Blocked/Planned\"]).round(1)\n",
    "\n",
    "for status in statuses_list:\n",
    "    extracted_issues[status] = extracted_issues[status].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "534955df-2192-4788-89eb-8448b9b2d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_daily_comments(comments_dates, start_date, end_date):\n",
    "    expected_nb_comments = nb_w_days(end_date.date(), start_date.date())\n",
    "    nbr_disctinct_comments_dates = len(set([\n",
    "        d.date() for d in comments_dates if start_date.date() <= d.date() and d.date() <= end_date.date()]))\n",
    "    return \"x\" if nbr_disctinct_comments_dates > expected_nb_comments else \"o\"\n",
    "\n",
    "extracted_issues[\"DailyCommentCheck\"] = extracted_issues.apply(\n",
    "    lambda r: check_daily_comments([datetime.datetime.strptime(d[:16], \"%Y-%m-%dT%H:%M\") for d in r['comments_dates']],\n",
    "                                   datetime.datetime.strptime(r[\"sprints_startDate\"][:16], \"%Y-%m-%dT%H:%M\"),\n",
    "                                   r[\"end date\"]) if len(r[\"sprints_startDate\"]) > 14 else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "290ad744-2323-4da0-bdef-c668b9e08487",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iteration_matching = {\n",
    "    \"tryout\": \"tryout\",\n",
    "    \"try_out\": \"tryout\",\n",
    "    \"test1\": \"test1\",\n",
    "    \"test2\": \"test2\",\n",
    "    \"test3\": \"test3\",\n",
    "    \"test4\": \"test4\",\n",
    "    \"test5\": \"test5\"\n",
    "}\n",
    "test_system_contains_matching = {\n",
    "    \"CAN\": \"NWT\",\n",
    "    \"FR\": \"NWT\",\n",
    "    \"LIN\": \"NWT\",\n",
    "    \"BAP\": \"BAP\",\n",
    "    \"ETH\": \"BTST\",\n",
    "    \"SOMEIP\": \"BTST\",\n",
    "    \"ViWi\": \"BTST\",\n",
    "    \"FAZIT\": \"Sec\"\n",
    "}\n",
    "test_system_equals_matching = {\n",
    "    \"Routing\": \"Routing\",\n",
    "    \"VKMS\": \"Sec\",\n",
    "    \"SOK\": \"Sec\",\n",
    "    \"TLS\": \"Sec\",\n",
    "    \"sSOA\": \"Sec\",\n",
    "    \"SOMEIP\": \"BTST\",\n",
    "    \"ViWi\": \"BTST\"\n",
    "}\n",
    "    #\"Added Conditional Column4\" = Table.AddColumn(#\"Expanded fnCountKPMcreated\", \"SolutionTrain\", each if Text.Contains([Labels], \"ST1.2\") then \"ST1.2\" else if Text.Contains([Labels], \"ST1.1\") then \"ST1.1\" else null),\n",
    "solutiontrain_contains_matching = {\n",
    "    \"ST1.1\": \"ST1.1\",\n",
    "    \"ST1.2\": \"ST1.2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ee6f4de-8a10-45dd-9f95-fb80266f0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_testtype(s):\n",
    "    lower_s = s.lower()\n",
    "    if lower_s.startswith(\"ft\"):\n",
    "        testtype = \"FT\"\n",
    "    elif lower_s.startswith(\"st\"):\n",
    "        testtype = \"ST\"\n",
    "    elif lower_s.startswith(\"pt\"):\n",
    "        testtype = \"PT\"\n",
    "    elif lower_s.startswith(\"dt\"):\n",
    "        testtype = \"DT\"\n",
    "    elif lower_s.startswith(\"try\"):\n",
    "        testtype = \"Try\"\n",
    "    else:\n",
    "        testtype = \"undefined\"\n",
    "    return testtype\n",
    "\n",
    "def extract_test_iteration(s):\n",
    "    lower_s = s.lower()\n",
    "    if \"tryout\" in lower_s or \"try_out\" in lower_s:\n",
    "        test_iteration = \"tryout\"\n",
    "    elif \"test1\" in lower_s:\n",
    "        test_iteration = \"test1\"\n",
    "    elif \"test2\" in lower_s:\n",
    "        test_iteration = \"test2\"\n",
    "    elif \"test3\" in lower_s:\n",
    "        test_iteration = \"test3\"\n",
    "    elif \"test4\" in lower_s:\n",
    "        test_iteration = \"test4\"\n",
    "    elif \"test5\" in lower_s:\n",
    "        test_iteration = \"test5\"\n",
    "    else:\n",
    "        test_iteration = \"undefined\"\n",
    "    return test_iteration\n",
    "\n",
    "def extract_with_contains_condition(s, contains_matching, default):\n",
    "    for pattern, result in contains_matching.items():\n",
    "        if pattern in s:\n",
    "            return result\n",
    "    return default\n",
    "\n",
    "def extract_with_equals_condition(s, contains_matching, default):\n",
    "    for pattern, result in contains_matching.items():\n",
    "        if pattern == s:\n",
    "            return result\n",
    "    return default\n",
    "\n",
    "def extract_test_iteration(s):\n",
    "    return extract_with_contains_condition(s, test_iteration_matching, \"undefined\")\n",
    "\n",
    "def extract_test_system(s):\n",
    "    result_contains = extract_with_contains_condition(s, test_system_contains_matching, None)\n",
    "    if result_contains:\n",
    "        return result_contains\n",
    "    else:\n",
    "        extract_with_equals_condition(s, test_system_equals_matching, None)\n",
    "\n",
    "def extract_solutiontrain(s):\n",
    "    return extract_with_contains_condition(s, solutiontrain_contains_matching, None)\n",
    "\n",
    "def treansfrom_status(s):\n",
    "    return (\"Test performed\" if s == \"Test results ok\" \n",
    "            else \"Failed\" if s == \"Test results not ok\" else s)\n",
    "\n",
    "\n",
    "def transform_epic_link(s):\n",
    "    return (s\n",
    "            .replace(\"TCC-13860\", \"EDAG\")\n",
    "            .replace(\"TCC-13870\", \"PORSCHETESTHAUS\")\n",
    "            .replace(\"TCC-13859\", \"DIGITEQ\")\n",
    "            .replace(\"TCC-14627\", \"in-tech\")\n",
    "            .replace(\"TCQ Vernetzung\", \"Networking\")\n",
    "            .replace(\"TCC-31666\", \"KPIT\")\n",
    "            .replace(\"TCC-31247\", \"AUDI\")\n",
    "            .replace(\"TCC-32455\", \"ESRLabs\")\n",
    "            .replace(\"TCQ Security\", \"Security\")\n",
    "           )\n",
    "    \n",
    "def transform_components(s):\n",
    "    return (s\n",
    "            .replace(\"TCQ Vernetzung\", \"Networking\")\n",
    "            .replace(\"TCQ Security\", \"Security\")\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ccd94b2-474b-408c-93a1-c8da63650ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_issues[\"TestType\"] = extracted_issues[\"summary\"].map(extract_testtype)\n",
    "\n",
    "extracted_issues[\"test iteration\"] = extracted_issues[\"labels\"].map(extract_test_iteration)\n",
    "\n",
    "extracted_issues[\"test system\"] = extracted_issues[\"Technology\"].map(extract_test_system)\n",
    "\n",
    "extracted_issues[\"Tech-Cluster\"] = extracted_issues[\"components\"].map(transform_components)\n",
    "\n",
    "extracted_issues[\"Custom field (Epic Link)\"] = extracted_issues[\"epic_link\"].map(transform_epic_link)\n",
    "\n",
    "extracted_issues[\"Solution Train\"] = extracted_issues[\"labels\"].map(extract_solutiontrain)\n",
    "\n",
    "mask_Erstdurchdringung = (extracted_issues[\"resolution_date\"].notna() & (extracted_issues[\"TestType\"] == \"FT\")\n",
    "                          & ~extracted_issues[\"status\"].isin(['Cancelled', 'Test results not ok']))\n",
    "extracted_issues[\"Erstdurchdringung\"] = None\n",
    "extracted_issues[\"Cluster\"] = extracted_issues[\"Cluster\"].fillna('')\n",
    "extracted_issues[\"Solution Train\"] = extracted_issues[\"Solution Train\"].fillna('')\n",
    "\n",
    "extracted_issues.loc[mask_Erstdurchdringung, \"Erstdurchdringung\"] = (extracted_issues\n",
    "                                                                     .loc[mask_Erstdurchdringung]\n",
    "                                                                     .groupby([\"summary\", \"Cluster\", \"Solution Train\"])[\"key\"]\n",
    "                                                                     .rank(method=\"dense\", ascending=True)\n",
    "                                                                    )\n",
    "extracted_issues.loc[mask_Erstdurchdringung, \"Erstdurchdringung\"] = extracted_issues.loc[mask_Erstdurchdringung, \"Erstdurchdringung\"].map(\n",
    "    lambda x: \"x\" if x==1 else \"o\" if x > 1 else None)\n",
    "# extracted_issues[\"Erstdurchdringung\"] = extracted_issues.groupby([\"summary\", \"Cluster\", \"Solution Train\"])[\"key\"].rank(method=\"dense\", ascending=True)\n",
    "# extracted_issues.loc[extracted_issues[\"resolution_date\"].isna() | (extracted_issues[\"TestType\"] != \"FT\"), \"Erstdurchdringung\"] = None\n",
    "# extracted_issues[\"Erstdurchdringung\"] = extracted_issues[\"Erstdurchdringung\"].map(lambda x: \"x\" if x==1 else \"o\" if x > 1 else None)\n",
    "\n",
    "extracted_issues[\"Current teststatus\"] = extracted_issues[\"status\"] .map(treansfrom_status)\n",
    "\n",
    "extracted_issues[\"created [year/week]\"] = extracted_issues[\"created\"].map(lambda d: d.strftime(\"%Y/%V\"))\n",
    "\n",
    "\n",
    "extracted_issues[\"resolved [year/week]\"] = extracted_issues[\"resolution_date\"].map(lambda d:\n",
    "                                                                           datetime.datetime.strptime(d[:10], '%Y-%m-%d').strftime(\"%Y/%V\") if d else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a796fee4-cc59-4197-a732-2cf91d41fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_betweendelimiters(s, delimter1, delimter2, occ1, occ2):\n",
    "    if delimter1 not in s:\n",
    "        return \"\"\n",
    "    else:\n",
    "        split1 = delimter1.join(s.split(delimter1)[occ1+1:])\n",
    "        if delimter2 == \"\":\n",
    "            return split1\n",
    "        if delimter2 in split1:\n",
    "            return delimter2.join(split1.split(delimter2)[:occ2+1])\n",
    "        else:\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc0ec7d6-90c0-4060-838f-d1d3cce69b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_issues[\"Test results FEA\"] = extracted_issues[\"description\"].map(lambda s: extract_betweendelimiters(s,\n",
    "                                                                         \"||Total amount of TCs||iO||niO||offen||Testblocker||Geblockt||Testfall Problem||Testinfrastruktur Problem||Durchführung abgebrochen||\",\n",
    "                                                                         \"|\", 0, 9))\n",
    "extracted_issues[\"Test results CB\"] = extracted_issues[\"description\"].map(lambda s: extract_betweendelimiters(s,\n",
    "                                                                         \"||Total amount of TCs||passed||failed||blocked||not applicable||not run yet||\",\n",
    "                                                                         \"|\", 0, 6))\n",
    "extracted_issues[\"Test results Raw\"] = extracted_issues[\"description\"].map(lambda s: extract_betweendelimiters(s,\n",
    "                                                                         \"||Total amount of TCs||iO||niO||offen||nicht geplant||\",\n",
    "                                                                         \"|\", 0, 5))\n",
    "extracted_issues[\"Link to filled FEA\"] = extracted_issues[\"description\"].map(lambda s: extract_betweendelimiters(s,\n",
    "                                                                         \"Link to filled FEA+*\",\n",
    "                                                                         \"*\", 0, 0))\n",
    "extracted_issues[\"Link to Raw Data\"] = extracted_issues[\"description\"].map(lambda s: extract_betweendelimiters(s,\n",
    "                                                                         \"Link to Raw Data+*\",\n",
    "                                                                         \"*\", 0, 0))\n",
    "extracted_issues[\"Link to filled Codebeamer Excel\"] = extracted_issues[\"description\"].map(lambda s: extract_betweendelimiters(s,\n",
    "                                                                         \"Link to filled Codebeamer Excel+*\",\n",
    "                                                                         \"*\", 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9200eb38-3f36-40db-bb36-add58e75259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_series(s, separator, n, cols):\n",
    "    splited_series = s.str.strip().str.split(separator)\n",
    "    splited_df = pd.concat([splited_series.map(lambda l: int(l[i]) if i < len(l) and  l[i].isnumeric() else np.nan) for i in range(n)], axis=1)\n",
    "    splited_df.columns = cols\n",
    "    return splited_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5725a05a-3ee6-4c69-a17d-f9a647ffeaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_issues.drop(fea_cols+raw_cols+cb_cols, axis=1, inplace=True)\n",
    "fea_cols = [\"Test results FEA.1\", \"Number of TCs FEA.2\", \"io FEA.3\", \"nio FEA.4\", \"offen FEA.5\", \"Testblocker FEA.6\",\n",
    "            \"Geblockt FEA.7\", \"Testfallproblem FEA.8\", \"Testinfrastruktur FEA.9\", \"abgebrochen FEA.10\"]\n",
    "raw_cols = [\"Test results Raw.1\", \"Number of TCs Raw.2\", \"io Raw.3\", \"nio Raw.4\", \"offen Raw.5\", \"nicht geplant Raw.6\"]\n",
    "cb_cols = [\"Test results CB.1\", \"Number of TCs CB.2\", \"passed CB.3\", \"failed CB.4\",\n",
    "              \"blocked CB.5\", \"not applicable CB.6\", \"not run yet CB.7\"]\n",
    "extracted_issues = pd.concat([extracted_issues, split_series(extracted_issues[\"Test results FEA\"], \"|\", 10,\n",
    "             fea_cols)], axis=1)\n",
    "extracted_issues = pd.concat([extracted_issues, split_series(extracted_issues[\"Test results Raw\"], \"|\", 6,\n",
    "             raw_cols)], axis=1)\n",
    "\n",
    "extracted_issues = pd.concat([extracted_issues, split_series(extracted_issues[\"Test results CB\"], \"|\", 7,\n",
    "                                                             cb_cols)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "394a2bd4-367f-450d-84e9-808f6650e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace = \"\"\"\\<type here\\>\\+\\*|Please write a detailed summary for the occurred problems after the hashtag summary\\.|Please provide confluence link\\(s\\) to the documentation where you document your new findings / insights for the team \\(e\\. g\\. new ECU configuration\\, coding\\)\\.|\\<enter Link\\(s\\) to Confluence here\\>\\+\\*|\\*\\(x\\) \\+|\\\"\\*\\+\\\"\\,\"\"\"\n",
    "extracted_issues[\"#Problems\"] = extracted_issues[\"description\"].map(lambda s: extract_betweendelimiters(s,\n",
    "                                                                         \"#Problems:\",\n",
    "                                                                         \"#Summary\", 0, 0)).str.replace(to_replace, \"\", regex=True).str.strip()\n",
    "extracted_issues[\"#Summary\"] = extracted_issues[\"description\"].map(lambda s: extract_betweendelimiters(s,\n",
    "                                                                         \"#Summary:\",\n",
    "                                                                         \"#Links:\", 0, 0)).str.replace(to_replace, \"\", regex=True).str.strip()\n",
    "extracted_issues[\"#Links\"] = extracted_issues[\"description\"].map(lambda s: extract_betweendelimiters(s,\n",
    "                                                                         \"#Links:\",\n",
    "                                                                         \"\", 0, 0)).str.replace(to_replace, \"\", regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36240535-5823-4bab-8f87-cc888c6af26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kpm_extracted_list(s):\n",
    "    kpm_part = extract_betweendelimiters(s, \"||KPM Number||Comments if necessary||\", \"\", 0, 1)\n",
    "    kpm_part_split = [s.replace(\"KPM_\", \"\").replace(\"KPM\", \"\").strip() for s in \"|\".join(kpm_part.split(\"#(lf)\")).split(\"|\")]\n",
    "    return [re.search(\"[0-9]{6,12}\", s).group().strip() for s in kpm_part_split if re.search(\"[0-9]{6,12}\", s)]\n",
    "\n",
    "def extract_kpm_verifictaion_list(s):\n",
    "    kpm_part = extract_betweendelimiters(s, \"||KPM Number||Verification status (passed, failed, blocked, not tested)||KPM Ticket updated (Y/N)||Comments if not passed||\",\n",
    "                                         \"\", 0, 1)\n",
    "    kpm_part_split = [s.replace(\"KPM_\", \"\").replace(\"KPM\", \"\").strip() for s in \"|\".join(kpm_part.split(\"#(lf)\")).split(\"|\")]\n",
    "    return [re.search(\"[0-9]{6,12}\", s).group().strip() for s in kpm_part_split if re.search(\"[0-9]{6,12}\", s)]\n",
    "    \n",
    "def extract_kpm_verifictaion_statuses(s):\n",
    "    kpm_part = extract_betweendelimiters(s, \"||KPM Number||Verification status (passed, failed, blocked, not tested)||KPM Ticket updated (Y/N)||Comments if not passed||\",\n",
    "                                         \"\", 0, 1)\n",
    "    kpm_part_split = [s.replace(\"KPM_\", \"\").replace(\"KPM\", \"\").strip().lower() for s in \"|\".join(kpm_part.split(\"#(lf)\")).split(\"|\")]\n",
    "    return [re.search(\"passed|pass|failed|fail|blocked|not tested\", s).group().strip() for s in kpm_part_split \n",
    "            if re.search(\"passed|failed|blocked|not tested\", s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd112891-8852-4f52-99fe-7e61b4718edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_issues[\"KPMs created list\"] = extracted_issues[\"New KPM Tickets\"].map(extract_kpm_extracted_list)\n",
    "extracted_issues[\"KPMs created count\"] = extracted_issues[\"KPMs created list\"].map(len)\n",
    "extracted_issues[\"KPMs verification list\"] = extracted_issues[\"KPM-Tickets to test\"].map(extract_kpm_verifictaion_list)\n",
    "extracted_issues[\"KPMs verification statuses\"] = extracted_issues[\"KPM-Tickets to test\"].map(extract_kpm_verifictaion_statuses)\n",
    "extracted_issues[\"KPMs verification status count passed|failed|blocked|not tested\"] = extracted_issues[\"KPMs verification statuses\"].map(lambda l:\n",
    "    \",\".join([str(l.count(\"passed\")), str(l.count(\"failed\")), str(l.count(\"blocked\")), str(l.count(\"not tested\"))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a053cd9-bd52-472f-b02c-343bcac207dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_fill(n):\n",
    "    return 0 if np.isnan(n) else n\n",
    "def is_not_nan(n):\n",
    "    return n and not(np.isnan(n))\n",
    "    \n",
    "def calculate_passed(r):\n",
    "    if is_not_nan(r[\"Number of TCs CB.2\"]):\n",
    "        return r[\"passed CB.3\"]\n",
    "    if is_not_nan(r[\"passed CB.3\"]):\n",
    "        return r[\"io FEA.3\"]\n",
    "    if is_not_nan(r[\"Number of TCs FEA.2\"]):\n",
    "        return r[\"io FEA.3\"]\n",
    "    return r[\"io Raw.3\"]\n",
    "    \n",
    "def calculate_failed(r):\n",
    "    if is_not_nan(r[\"Number of TCs CB.2\"]):\n",
    "        return r[\"failed CB.4\"]\n",
    "    if is_not_nan(r[\"Number of TCs FEA.2\"]):\n",
    "        return r[\"nio FEA.4\"]\n",
    "    return r[\"nio Raw.4\"]\n",
    "\n",
    "def calculate_blocked(r):\n",
    "    if is_not_nan(r[\"Number of TCs CB.2\"]):\n",
    "        return r[\"blocked CB.5\"]\n",
    "    if is_not_nan(r[\"Number of TCs FEA.2\"]):\n",
    "        return (nan_fill(r[\"Geblockt FEA.7\"]) + nan_fill(r[\"Testblocker FEA.6\"])\n",
    "                + nan_fill(r[\"Testfallproblem FEA.8\"]) + nan_fill(r[\"Testinfrastruktur FEA.9\"]))\n",
    "    return 0\n",
    "\n",
    "def calculate_not_applicable(r):\n",
    "    if is_not_nan(r[\"Number of TCs CB.2\"]):\n",
    "        return r[\"not applicable CB.6\"]\n",
    "    if is_not_nan(r[\"Number of TCs FEA.2\"]):\n",
    "        return r[\"abgebrochen FEA.10\"]+r[\"offen FEA.5\"]\n",
    "    return nan_fill(r[\"nicht geplant Raw.6\"]) + nan_fill(r[\"offen Raw.5\"])\n",
    "\n",
    "def calculate_not_run_yet(r):\n",
    "    if is_not_nan(r[\"Number of TCs CB.2\"]):\n",
    "        return r[\"not run yet CB.7\"]\n",
    "    if is_not_nan(r[\"Number of TCs FEA.2\"]):\n",
    "        return 0\n",
    "    return 0\n",
    "    \n",
    "extracted_issues[\"passed\"] = extracted_issues.apply(calculate_passed, axis=1)\n",
    "extracted_issues[\"failed\"] = extracted_issues.apply(calculate_failed, axis=1)\n",
    "extracted_issues[\"blocked\"] = extracted_issues.apply(calculate_blocked, axis=1)\n",
    "extracted_issues[\"not_applicable\"] = extracted_issues.apply(calculate_not_applicable, axis=1)\n",
    "extracted_issues[\"not run yet\"] = extracted_issues.apply(calculate_not_run_yet, axis=1)\n",
    "extracted_issues[\"Total applicable TCs\"] = (extracted_issues[\"passed\"].fillna(0) + extracted_issues[\"failed\"].fillna(0) \n",
    "                                           + extracted_issues[\"blocked\"].fillna(0) + extracted_issues[\"not run yet\"].fillna(0))\n",
    "extracted_issues[\"Total TCs\"] = (extracted_issues[\"passed\"].fillna(0) + extracted_issues[\"failed\"].fillna(0) \n",
    "                                 + extracted_issues[\"blocked\"].fillna(0) + extracted_issues[\"not run yet\"].fillna(0)\n",
    "                                 + extracted_issues[\"not_applicable\"].fillna(0))\n",
    "extracted_issues[\"Testcoverage (passed+failed)/ applicable\"] = extracted_issues.apply(lambda r: (nan_fill(r[\"passed\"])\n",
    "                                                                                                         + nan_fill(r[\"failed\"]))\n",
    "                                                                                      /  float(r[\"Total applicable TCs\"]) \n",
    "                                                                                      if r[\"Total applicable TCs\"] > 0 else 0, axis=1).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89dffd38-9c30-479b-ab64-d0887f3e567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extracted_issues[\"Results table filled\"]  = extracted_issues.apply(lambda r: \"-\" if r[\"status\"]!=\"Test results ok\"\n",
    "                                                                  else \"x\" if r[\"Total applicable TCs\"]>0 else \"o\", axis=1)\n",
    "extracted_issues[\"Logfile available\"]  = extracted_issues.apply(lambda r: \"-\" if r[\"status\"]!=\"Test results ok\"\n",
    "                                                                  else \"x\" if \"volkswagengroup.sharepoint.com\" in r[\"Link to Raw Data\"]\n",
    "                                                                  else \"o\", axis=1)\n",
    "\n",
    "extracted_issues[\"Jira ticket correct filled\"] = extracted_issues.apply(lambda r: \"-\" if r[\"status\"]!=\"Test results ok\"\n",
    "                                                                  else \"x\" if (r[\"Results table filled\"] == 'x'\n",
    "                                                                               and r[\"Logfile available\"] == 'x'\n",
    "                                                                               and r[\"#Problems\"] \n",
    "                                                                               and r[\"#Summary\"] )\n",
    "                                                                  else \"o\", axis=1)\n",
    "extracted_issues[\"Codebeamer Excels/FEAs available\"] = extracted_issues.apply(lambda r: \"-\" if r[\"status\"]!=\"Test results ok\"\n",
    "                                                                  else \"x\" if \"volkswagengroup.sharepoint.com\" in r[\"Link to filled FEA\"]\n",
    "                                                                              and \"volkswagengroup.sharepoint.com\" in r[\"Link to filled Codebeamer Excel\"]\n",
    "                                                                  else \"o\", axis=1)\n",
    "extracted_issues[\"KPMs finished\"] = extracted_issues.apply(lambda r: \"-\" if r[\"status\"]!=\"Test results ok\"\n",
    "                                                                  else \"x\" if r[\"Acceptance Criterias name\"]\n",
    "                                                                  or \"false\" not in  r[\"Acceptance Criterias checks\"]\n",
    "                                                                  else \"o\", axis=1)\n",
    "extracted_issues[\"Percentage of not aborted / executed TCs\"] = extracted_issues.apply(lambda r: (nan_fill(r[\"passed\"]) + nan_fill(r[\"failed\"])\n",
    "                                                                                      + nan_fill(r[\"blocked\"])) /  float(r[\"Total TCs\"]) if r[\"Total TCs\"] > 0\n",
    "                                                                  else 0, axis=1).round(2)\n",
    "extracted_issues[\"Percentage of passed applicable TCs\"] = extracted_issues.apply(\n",
    "    lambda r: nan_fill(r[\"passed\"]) / (nan_fill(r[\"passed\"]) + nan_fill(r[\"failed\"]) + nan_fill(r[\"not_applicable\"]) + nan_fill(r[\"not run yet\"])) \n",
    "    if nan_fill(r[\"passed\"]) + nan_fill(r[\"failed\"]) + nan_fill(r[\"not_applicable\"]) + nan_fill(r[\"not run yet\"]) > 0 else 0, axis=1).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dab955c-2c41-412a-9b95-4bc137845eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_issues[\"Duration current Assignee_nw\"] = extracted_issues.apply(lambda r: nb_w_days(r[\"end date\"].date(),\n",
    "                                                                                              r[\"Current assignee date\"].date()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "669c3d18-8314-45eb-a7e8-d4f5244825ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_columns = ['summary', 'key', 'sprint_names', 'SW', 'TestType', 'test iteration', 'ecu', 'Technology', 'test system', 'Tech-Cluster', 'Custom field (Epic Link)',\n",
    " 'Solution Train', 'Cluster', 'Current teststatus', 'time in current status', 'assignee', 'time with current Assignee', 'Assignee history', 'was blocked?',\n",
    " 'Erstdurchdringung', 'created [year/week]', 'resolution_date', 'resolved [year/week]', 'Testcoverage (passed+failed)/ applicable',\"Total applicable TCs\",\n",
    " 'passed', 'failed', 'blocked', 'not_applicable', 'not run yet',                 'Results table filled',\n",
    " 'Jira ticket correct filled', 'Logfile available',  'Codebeamer Excels/FEAs available', 'KPMs finished', \"DailyCommentCheck\", 'Percentage of not aborted / executed TCs',\n",
    "                   \"Percentage of passed applicable TCs\",\n",
    "'Planned', 'Backlog', 'Accepted for Implementation', 'In Progress', 'Waiting', 'In Analysis', 'Implementation Review','Provide Documentation', 'Test Blocked',\n",
    " 'Total', \"Total excluding Blocked/Planned\", \"Percentage time in Deffect Discussion\", '#Problems', '#Summary', '#Links', \"KPMs created list\", \"KPMs created count\",\n",
    "                   \"KPMs verification list\", \"KPMs verification statuses\",\n",
    "                   \"KPMs verification status count passed|failed|blocked|not tested\"]\n",
    "\n",
    "renamed_columns = ['Summary', 'TCC', 'Sprint', 'SW', 'Test Type', 'Test Iteration', 'ECU', 'Technology', 'Test system', 'Tech-Cluster', 'Trade',\n",
    " 'Solution Train', 'Cluster', 'Current teststatus', 'time in current status', 'current Assignee', 'time with current Assignee', 'Assignee history', 'was blocked?',\n",
    "                   'first coverage? (Erstdurchdringung)','created [year/week]', 'resolved', 'resolved [year/week]', 'Testcoverage (passed+failed)/ applicable',\"Total applicable TCs\",\n",
    "                   'passed', 'failed', 'blocked', 'not applicable', 'not run yet',  'Results table filled',\n",
    " 'Jira ticket correct filled', 'Logfile available',  'Codebeamer Excels/FEAs available', 'KPMs finished', \"Daily comments\", 'Percentage of not aborted / executed TCs',\n",
    "                   \"Percentage of passed applicable TCs\",\n",
    "\"Planned\",\t'Backlog', 'Test in Preparation',\t'Test Running',\t'Waiting', 'Test Result in Analysis', 'Defects Discussion',\n",
    "                   'Test in Documentation', 'Test Blocked', 'Total', \"Total excluding Blocked/Planned\", \"Percentage time in Deffect Discussion\",\n",
    "  '#Problems', '#Summary', '#Links', \"KPMs created list\", \"KPMs created count\", \"KPMs verification list\", \"KPMs verification statuses\",\n",
    "                   \"KPMs verification status count passed|failed|blocked|not tested\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e38df8e1-221b-43e8-b959-a5924fc2f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IntegrityCriteria = extracted_issues[initial_columns].copy()\n",
    "IntegrityCriteria.columns = renamed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "783fcd4b-4466-4676-825e-6b24083b5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_issues.to_csv(\"jira_transformed_all_status_20241028.csv\", index=False, header=1, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23fc22ab-6e73-4a2a-8520-c071adbfc465",
   "metadata": {},
   "outputs": [],
   "source": [
    "IntegrityCriteria.to_excel(\"IntegrityCriteria_20241028.xlsx\", index=False, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "945ebdf3-06b3-49bc-b3c0-70e2a1618b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('IC_auto_test_1.xlsx', engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "    IntegrityCriteria.to_excel(writer, sheet_name='IntegrityCriteria', index=False, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce99f82f-e62d-4b45-8509-87b514ad4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ew = pd.ExcelWriter('IC_auto_fill_test.xlsx', mode='a', if_sheet_exists='overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b4394-feef-4a1c-8012-d061a8028ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(initial_columns, renamed_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44632955-0a43-4350-9f69-9c4ea07ce134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7468"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e418410a-62f0-4e98-b9ad-39f85349be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6cfeac20-1f47-478e-8e2f-b9bbbf7e9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_issues.to_excel(\n",
    "    f\"IntegrityCriteria_test.xlsx\",\n",
    "    sheet_name=\"IC_All_Status_All_Sprints\",\n",
    "    index=False,\n",
    "    header=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2eb2df48-6b5e-4952-b338-0d5f72603cd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformed_issues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m percent_format \u001b[38;5;241m=\u001b[39m workbook\u001b[38;5;241m.\u001b[39madd_format({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage of not aborted / executed TCs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage of passed applicable TCs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage time in Deffect Discussion\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m---> 16\u001b[0m     col_posi \u001b[38;5;241m=\u001b[39m \u001b[43mtransformed_issues\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mindice(col)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Apply the number format to Grade column.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     worksheet\u001b[38;5;241m.\u001b[39mset_column(col_posi, col_posi, \u001b[38;5;28;01mNone\u001b[39;00m, percent_format)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transformed_issues' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "writer = pd.ExcelWriter(f\"IntegrityCriteria_test.xlsx\", engine=\"xlsxwriter\")\n",
    "extracted_issues.to_excel(\n",
    "    writer,\n",
    "    sheet_name=\"IC_All_Status_All_Sprints\",\n",
    "    index=False,\n",
    "    header=1,\n",
    ")\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"IC_All_Status_All_Sprints\"]\n",
    "\n",
    "# Add a percent number format.\n",
    "percent_format = workbook.add_format({\"num_format\": \"0%\"})\n",
    "for col in [\"Percentage of not aborted / executed TCs\", \"Percentage of passed applicable TCs\",\n",
    "            \"Percentage time in Deffect Discussion\", \"Testcoverage (passed+failed)/ applicable\"]:\n",
    "    col_posi = extracted_issues.columns.indice(col)\n",
    "    # Apply the number format to Grade column.\n",
    "    worksheet.set_column(col_posi, col_posi, None, percent_format)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "611af569-b1d6-4373-b3d3-40e681f12b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_format = workbook.add_format({\"num_format\": \"0%\"})\n",
    "for col in [\"Percentage of not aborted / executed TCs\", \"Percentage of passed applicable TCs\",\n",
    "            \"Percentage time in Deffect Discussion\"]:\n",
    "    col_posi = list(extracted_issues.columns).index(col)\n",
    "    # Apply the number format to Grade column.\n",
    "    worksheet.set_column(col_posi, col_posi, None, percent_format)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a29081ac-3581-48e3-9a36-001ac4457687",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'IC_All_Status_All_Sprints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m worksheet \u001b[38;5;241m=\u001b[39m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msheets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIC_All_Status_All_Sprints\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'IC_All_Status_All_Sprints'"
     ]
    }
   ],
   "source": [
    "worksheet = writer.sheets[\"IC_All_Status_All_Sprints\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c7997e15-5a12-44a8-942b-bdc5abaabe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = writer.book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81312e98-0a09-4bc3-a889-0eb65624d328",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Workbook' object has no attribute 'add_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m percent_format \u001b[38;5;241m=\u001b[39m \u001b[43mworkbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_format\u001b[49m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage of not aborted / executed TCs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage of passed applicable TCs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage time in Deffect Discussion\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m      4\u001b[0m     col_posi \u001b[38;5;241m=\u001b[39m transformed_issues\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mindice(col)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Workbook' object has no attribute 'add_format'"
     ]
    }
   ],
   "source": [
    "percent_format = workbook.add_format({\"num_format\": \"0%\"})\n",
    "for col in [\"Percentage of not aborted / executed TCs\", \"Percentage of passed applicable TCs\",\n",
    "            \"Percentage time in Deffect Discussion\"]:\n",
    "    col_posi = transformed_issues.columns.indice(col)\n",
    "    # Apply the number format to Grade column.\n",
    "    worksheet.set_column(col_posi, col_posi, None, percent_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a503883f-db90-4cf3-905e-49df5e9339d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43f6ed78-1d53-4033-b19f-07fbe35bc89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5925360-3225-4df0-b559-00124046035b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer.sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29124fc-c3b0-498f-a730-8685136a5247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
